{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from unoai.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _bytes_feature(value) -> tf.train.Feature:\n",
    "    \"Returns a bytes_list from a string / byte.\"\n",
    "    if isinstance(value, type(tf.constant(0))): value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value) -> tf.train.Feature:\n",
    "    if not isinstance(value, list): value = [value]\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "def _int64_feature(value) -> tf.train.Feature:\n",
    "    \"Returns an int64_list from a bool / enum / int / uint.\"\n",
    "    if not isinstance(value, list): value = [value]\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "def get_tf_example_from_raw_img(raw_img, y: None) -> tf.train.Example:\n",
    "    if y is None: feat_dict = {'image': _bytes_feature(raw_img)}\n",
    "    else:         feat_dict = {'image': _bytes_feature(raw_img), 'label': _int64_feature(y)}\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feat_dict))\n",
    "\n",
    "def get_tf_example_from_numpy(x, y: None) -> tf.train.Example:\n",
    "    if y is None: feat_dict = {'image': _float_feature(x.tolist())}\n",
    "    else:         feat_dict = {'image': _float_feature(x.tolist()), 'label': _int64_feature(y)}\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feat_dict))\n",
    "\n",
    "def store_np_imgs_as_tfrecord(output_path: str, x: np.array, y: np.array=None) -> None:\n",
    "    n = x.shape[0]\n",
    "    x_reshape = x.reshape(n,-1)\n",
    "    with tf.io.TFRecordWriter(output_path) as w:\n",
    "        for i in tqdm(range(n)):\n",
    "            if y is None: ex = get_tf_example_from_numpy(x_reshape[i])\n",
    "            else:         ex = get_tf_example_from_numpy(x_reshape[i], y[i])\n",
    "            w.write(ex.SerializeToString())\n",
    "\n",
    "def parse_tf_example_img(tf_example: tf.train.Example,h: int, w: int, c: int=3,dtype=tf.float32):\n",
    "    feat_desc = {\n",
    "        'image': tf.io.FixedLenFeature([h * w * c], dtype),\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    feat = tf.io.parse_single_example(tf_example,features=feat_desc)\n",
    "    x, y = feat['image'], feat['label']\n",
    "    x = tf.reshape(x, [h, w, c])\n",
    "    return x, y\n",
    "\n",
    "def read_tfrecord_as_dataset(ds_path: str, parser: Callable, batch_size: int = None,\n",
    "                             shuffle: bool = True, shuffle_buffer_size: int = 50000,\n",
    "                             prefetch: bool = False) -> tf.data.Dataset:\n",
    "    ds = tf.data.TFRecordDataset(ds_path)\n",
    "    if shuffle: ds = ds.shuffle(shuffle_buffer_size)\n",
    "    ds = ds.map(parser, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    if batch_size is not None: ds = ds.batch(batch_size)\n",
    "    if prefetch: ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return ds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)â€¦",
   "language": "python",
   "name": "venv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
