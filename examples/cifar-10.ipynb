{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unoai.imports import *\n",
    "from unoai.data.datasets import *\n",
    "from unoai.train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import gc\n",
    "import contextlib\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfile = tf.io.gfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_LOC = \"datasets/cifar10\"\n",
    "MODEL_LOC = \"models/cifar10\"\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 5\n",
    "RESOLUTION = (32, 32)\n",
    "NUM_CHANNELS = 3\n",
    "NUM_TRAIN = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 0.000125\n",
    "LEARNING_RATE = 0.9\n",
    "EPOCHS = 15\n",
    "WARMUP = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(MODEL_LOC):\n",
    "    shutil.rmtree(MODEL_LOC)\n",
    "gfile.makedirs(MODEL_LOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:30<00:00, 1625.81it/s]\n",
      "100%|██████████| 10000/10000 [00:06<00:00, 1459.50it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = get_cifar10(ds_dir=DATASET_LOC, batch_size=BATCH_SIZE, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_pytorch(shape, dtype=tf.float32, partition_info=None):\n",
    "  fan = np.prod(shape[:-1])\n",
    "  bound = 1 / math.sqrt(fan)\n",
    "  return tf.random.uniform(shape, minval=-bound, maxval=bound, dtype=dtype)\n",
    "\n",
    "class ConvBN(tf.keras.Model):\n",
    "  def __init__(self, c_out, virtual_batch_size=None):\n",
    "    super().__init__()\n",
    "    self.conv = tf.keras.layers.Conv2D(filters=c_out, kernel_size=3, padding=\"SAME\", kernel_initializer=init_pytorch, use_bias=False)\n",
    "    self.bn = tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, virtual_batch_size=None)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return tf.nn.relu(self.bn(self.conv(inputs)))\n",
    "\n",
    "class ConvPoolBNAct(tf.keras.Model):\n",
    "  def __init__(self, c_out, virtual_batch_size=None):\n",
    "    super().__init__()\n",
    "    self.conv = tf.keras.layers.Conv2D(filters=c_out, kernel_size=3, padding=\"SAME\", kernel_initializer=init_pytorch, use_bias=False)\n",
    "    self.bn = tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, virtual_batch_size=None)\n",
    "    self.pool = tf.keras.layers.MaxPool2D()\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return tf.nn.relu(self.bn(self.pool(self.conv(inputs))))\n",
    "\n",
    "class ResBlk(tf.keras.Model):\n",
    "  def __init__(self, c_out, pool, res = False):\n",
    "    super().__init__()\n",
    "    self.conv_bn = ConvBN(c_out, 8)\n",
    "    self.conv_pool_bn_act = ConvPoolBNAct(c_out, 8)\n",
    "    self.pool = pool\n",
    "    self.res = res\n",
    "    if self.res:\n",
    "      self.res1 = ConvBN(c_out)\n",
    "      self.res2 = ConvBN(c_out)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    #h = self.pool(self.conv_bn(inputs))\n",
    "    h = self.conv_pool_bn_act(inputs)\n",
    "    if self.res:\n",
    "      h = h + self.res2(self.res1(h))\n",
    "    return h\n",
    "\n",
    "class DavidNet(tf.keras.Model):\n",
    "  def __init__(self, c=32, weight=0.125):\n",
    "    super().__init__()\n",
    "    pool = tf.keras.layers.MaxPooling2D()\n",
    "    self.init_conv_bn = ConvBN(c)\n",
    "    self.blk1 = ResBlk(c*3, pool, res = True)\n",
    "    self.blk2 = ResBlk(c*6, pool)\n",
    "    self.blk3 = ResBlk(c*9, pool, res = True)\n",
    "    self.pool = tf.keras.layers.GlobalMaxPool2D()\n",
    "    self.linear = tf.keras.layers.Dense(10, kernel_initializer=init_pytorch, use_bias=False)\n",
    "    self.weight = weight\n",
    "\n",
    "  def call(self, x):\n",
    "    h = self.pool(self.blk3(self.blk2(self.blk1(self.init_conv_bn(x)))))\n",
    "    h = self.linear(h) * self.weight\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineAnnealer:\n",
    "    def __init__(self, start, end, steps):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.steps = steps\n",
    "        self.n = 0\n",
    "        \n",
    "    def step(self):\n",
    "        self.n += 1\n",
    "        cos = np.cos(np.pi * (self.n / self.steps)) + 1\n",
    "        return self.end + (self.start - self.end) / 2. * cos\n",
    "\n",
    "\n",
    "class OneCycleScheduler(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, lr_max, steps, mom_min=0.85, mom_max=0.95, phase_1_pct=0.3, div_factor=25.):\n",
    "        super(OneCycleScheduler, self).__init__()\n",
    "        lr_min = lr_max / div_factor\n",
    "        final_lr = lr_max / (div_factor * 1e4)\n",
    "        phase_1_steps = steps * phase_1_pct\n",
    "        phase_2_steps = steps - phase_1_steps\n",
    "        \n",
    "        self.phase_1_steps = phase_1_steps\n",
    "        self.phase_2_steps = phase_2_steps\n",
    "        self.phase = 0\n",
    "        self.step = 0\n",
    "        \n",
    "        self.phases = [[CosineAnnealer(lr_min, lr_max, phase_1_steps), CosineAnnealer(mom_max, mom_min, phase_1_steps)], \n",
    "                 [CosineAnnealer(lr_max, final_lr, phase_2_steps), CosineAnnealer(mom_min, mom_max, phase_2_steps)]]\n",
    "        \n",
    "        self.lrs = []\n",
    "        self.moms = []\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.phase = 0\n",
    "        self.step = 0\n",
    "\n",
    "        self.set_lr(self.lr_schedule().start)\n",
    "        self.set_momentum(self.mom_schedule().start)\n",
    "        \n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        self.lrs.append(self.get_lr())\n",
    "        self.moms.append(self.get_momentum())\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.step += 1\n",
    "        if self.step >= self.phase_1_steps:\n",
    "            self.phase = 1\n",
    "            \n",
    "        self.set_lr(self.lr_schedule().step())\n",
    "        self.set_momentum(self.mom_schedule().step())\n",
    "        \n",
    "    def get_lr(self):\n",
    "        try:\n",
    "            return tf.keras.backend.get_value(self.model.optimizer.lr)\n",
    "        except AttributeError:\n",
    "            return None\n",
    "        \n",
    "    def get_momentum(self):\n",
    "        try:\n",
    "            return tf.keras.backend.get_value(self.model.optimizer.momentum)\n",
    "        except AttributeError:\n",
    "            return None\n",
    "        \n",
    "    def set_lr(self, lr):\n",
    "        try:\n",
    "            tf.keras.backend.set_value(self.model.optimizer.lr, lr)\n",
    "        except AttributeError:\n",
    "            pass # ignore\n",
    "        \n",
    "    def set_momentum(self, mom):\n",
    "        try:\n",
    "            tf.keras.backend.set_value(self.model.optimizer.momentum, mom)\n",
    "        except AttributeError:\n",
    "            pass # ignore\n",
    "\n",
    "    def lr_schedule(self):\n",
    "        return self.phases[self.phase][0]\n",
    "    \n",
    "    def mom_schedule(self):\n",
    "        return self.phases[self.phase][1]\n",
    "    \n",
    "    def plot(self):\n",
    "        ax = plt.subplot(1, 2, 1)\n",
    "        ax.plot(self.lrs)\n",
    "        ax.set_title('Learning Rate')\n",
    "        ax = plt.subplot(1, 2, 2)\n",
    "        ax.plot(self.moms)\n",
    "        ax.set_title('Momentum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "      4/Unknown - 43s 11s/step - loss: 7.9080 - accuracy: 0.0913"
     ]
    }
   ],
   "source": [
    "steps = np.ceil(NUM_TRAIN / BATCH_SIZE) * EPOCHS\n",
    "lr_schedule = OneCycleScheduler(LEARNING_RATE, steps)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(lr=LEARNING_RATE)\n",
    "\n",
    "loss_fn = tf.keras.losses.sparse_categorical_crossentropy\n",
    "\n",
    "model = train_model(train_ds=train_data, test_ds=test_data, epochs=EPOCHS, model_fn=DavidNet, opt_fn=optimizer, loss_fn=loss_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)…",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
