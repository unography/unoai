# AUTOGENERATED! DO NOT EDIT! File to edit: dev/03_train.ipynb (unless otherwise specified).

__all__ = ['train_model_custom', 'train_model']

# Cell
from .imports import *

# Cell
def train_model_custom(train_ds: tf.data.Dataset, test_ds: tf.data.Dataset,
                       epochs: int, opt: tf.keras.optimizers, loss_fn: Callable,
                       callbacks: List[tf.keras.callbacks.Callback]=None,
                       model_fn: Callable=None, model: tf.keras.Model=None):
    assert model_fn is not None or model is not None, "Both model function and model cannot be None."
    if model is None: model = model_fn()
    # todo: standardize metrics
    train_loss = tf.keras.metrics.Mean(name='train_loss')
    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')
    test_loss = tf.keras.metrics.Mean(name='test_loss')
    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')

    @tf.function
    def train_step(images, labels):
        with tf.GradientTape() as tape:
            predictions = model(images)
            loss = loss_fn(labels, predictions)
        gradients = tape.gradient(loss, model.trainable_variables)
        opt.apply_gradients(zip(gradients, model.trainable_variables))
        train_loss(loss)
        train_accuracy(labels, predictions)

    @tf.function
    def test_step(images, labels):
        predictions = model(images)
        t_loss = loss_fn(labels, predictions)
        test_loss(t_loss)
        test_accuracy(labels, predictions)

    if callbacks is not None: _ = [callback.on_train_begin() for callback in callbacks]

    for epoch in tqdm(range(epochs)):
        train_loss.reset_states()
        train_accuracy.reset_states()
        test_loss.reset_states()
        test_accuracy.reset_states()

        if callbacks is not None: _ = [callback.on_epoch_begin(epoch) for callback in callbacks]
        for step, inputs in enumerate(train_ds):
            if callbacks is not None: _ = [callback.on_train_batch_begin(step) for callback in callbacks]
            train_step(*inputs)
            if callbacks is not None: _ = [callback.on_train_batch_end(step) for callback in callbacks]

        if callbacks is not None: _ = [callback.on_epoch_end(epoch) for callback in callbacks]

        for step, inputs in enumerate(test_ds):
            test_step(*inputs)

        template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'
        print(template.format(epoch+1,
                            train_loss.result(),
                            train_accuracy.result()*100,
                            test_loss.result(),
                            test_accuracy.result()*100))

    return model

# Cell
def train_model(train_ds: tf.data.Dataset, test_ds: tf.data.Dataset,
                epochs: int, opt_fn: tf.keras.optimizers, loss_fn: Callable,
                callbacks: List[Callable]=None,
                model_fn: Callable=None, model: tf.keras.Model=None):

    assert model_fn is not None or model is not None, "Neither model nor model function provided."
    if model is None: model = model_fn()
    model.compile(optimizer=opt_fn, loss=loss_fn, metrics=['accuracy'])
    model.fit(train_ds,epochs=epochs, callbacks=callbacks)
    return model